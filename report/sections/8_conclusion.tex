\section{Conclusion}
We constructed two different models to complete the task, a recurrent neural network with LSTM and 256 hidden units, and a transformer model with 6 transformer layers. The recurrent neural network had the best test accuracy of 83\%, while the transformer model had a test accuracy of 81\%. We tried using a pretrained model distilBERT on our task to see how it would fare. It got a test accuracy of 89\%. As expected our models were worse. This can be explained by the fact that distilBERT has more parameters and a much bigger training set than our models. 

Overall we are satisfied with our result but it could have been improved. Initially an accuracy of 83\% seems quite bad, but even the pretrained model had a test accuracy of less than 90\% so compared to that, it does not seem too bad. 

\subsection{Individual Contributions}
\begin{table}[H]
    \centering
    \begin{tabular}{|l|l|l|}
    \hline
                    & \textbf{Henrik Daniel Christensen}    & \textbf{Frode Engtoft Johansen} \\ \hline
    \textbf{Code}   & Task 1, 2, 5                          & Task 3, 4\\ \hline
    \textbf{Report} & Section 1, 2, 3, 4.1, 6                 & Section 4.2, 5, 7 \\ \hline
    \end{tabular}
    \caption{Individual contributions.}
    \label{tab:individual_contributions}
\end{table}
